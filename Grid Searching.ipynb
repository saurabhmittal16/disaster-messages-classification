{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize\n",
    "model_cols = ['request', 'food', 'shelter', 'water', 'medical_help', 'clothing', 'search_and_rescue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./preprocessed/training.csv\")\n",
    "test = pd.read_csv(\"./preprocessed/test.csv\")\n",
    "validation = pd.read_csv(\"./preprocessed/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logis_clf = LogisticRegression(C=2, solver='lbfgs', max_iter=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'count' : CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = tokenizer),\n",
    "    'count_multi' : CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,2), tokenizer = tokenizer, max_features=80000),\n",
    "    'tfidf' : TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range = (1,1), tokenizer = tokenizer),\n",
    "    'tfidf_multi' : TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range = (1,2), tokenizer = tokenizer, max_features=100000)\n",
    "}\n",
    "\n",
    "cols = ['message', 'message_stem', 'message_lemma']\n",
    "\n",
    "training_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training data features:\")\n",
    "for v in vectorizers:\n",
    "    for col in cols:\n",
    "        curr_vectorizer = vectorizers[v]\n",
    "        key = v + '_' + col\n",
    "        training_features[key] = curr_vectorizer.fit_transform(train[col])\n",
    "        print(key + \":\", len(curr_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x):\n",
    "    # x is the feature matrix of training data (count or tfidf)\n",
    "    \n",
    "    classifiers = {}\n",
    "    roc_auc_scores = {}\n",
    "\n",
    "    for col in model_cols:\n",
    "        y = train[col]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=79)\n",
    "\n",
    "        clf = logis_clf.fit(x_train, y_train)\n",
    "        predicted = clf.predict_proba(x_test)[:, 1]\n",
    "        score = metrics.roc_auc_score(y_test, predicted)\n",
    "\n",
    "        classifiers[col] = clf\n",
    "        roc_auc_scores[col] = score\n",
    "    \n",
    "    avg = 0\n",
    "    for key in roc_auc_scores:\n",
    "        print(\"Score for {}: \".format(key), roc_auc_scores[key])\n",
    "        avg += roc_auc_scores[key]\n",
    "\n",
    "    avg /= len(model_cols)\n",
    "    print(\"Final Score: \", avg)\n",
    "\n",
    "    roc_auc_scores['avg'] = avg\n",
    "    return classifiers, roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_model in training_features:\n",
    "    print('\\n' +type_model)\n",
    "    classifier, scores = training(training_features[type_model])\n",
    "    result_classifiers[type_model] = [classifier, scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_result = {}\n",
    "for key in result_classifiers:\n",
    "    saved_result[key] = result_classifiers[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/search.pickle', 'wb') as file:\n",
    "    pickle.dump(saved_result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating graph to choose the best config\n",
    "with open('./pickles/search.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pd.DataFrame()\n",
    "vis['key'] = data.keys()\n",
    "\n",
    "plot_cols = model_cols.copy()\n",
    "plot_cols.insert(0, 'avg')\n",
    "\n",
    "for col in plot_cols:\n",
    "    temp = []\n",
    "    for key in data:\n",
    "        temp.append(data[key][col])\n",
    "    vis[col] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_melted = pd.melt(vis, id_vars='key', var_name='type', value_name='score')\n",
    "vis_melted['color'] = '#95ACFF'\n",
    "\n",
    "types = vis_melted['type'].unique().tolist()\n",
    "for i in range(len(types)):\n",
    "    index = np.argmax(vis_melted[vis_melted['type'] == types[i]]['score'])\n",
    "    vis_melted.at[12*i + index, 'color'] = '#4D61A9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=8, sharey=\"all\", figsize=(16,16))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for index in range(8):\n",
    "    axs[index].barh(vis['key'], vis[plot_cols[index]], color=vis_melted[vis_melted[\"type\"] == plot_cols[index]]['color'])\n",
    "    axs[index].set_xlim(0.7, 0.95)\n",
    "    axs[index].spines['right'].set_visible(False)\n",
    "    axs[index].spines['top'].set_visible(False)\n",
    "    axs[index].set_title(plot_cols[index].replace('_', ' ').capitalize())\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "fig.savefig('./result/plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}