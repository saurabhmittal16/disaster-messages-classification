{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = ['request', 'food', 'shelter', 'water', 'medical_help', 'clothing', 'search_and_rescue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./preprocessed/training.csv\")\n",
    "test = pd.read_csv(\"./preprocessed/test.csv\")\n",
    "validation = pd.read_csv(\"./preprocessed/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logis_clf = LogisticRegression(C=2, solver='lbfgs', max_iter=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    # 'count' : CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = tokenizer),\n",
    "    # 'count_multi' : CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,2), tokenizer = tokenizer, max_features=80000),\n",
    "    'tfidf' : TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range = (1,1), tokenizer = tokenizer),\n",
    "    'tfidf_multi' : TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range = (1,2), tokenizer = tokenizer, max_features=100000)\n",
    "}\n",
    "\n",
    "cols = ['message', 'message_stem', 'message_lemma']\n",
    "\n",
    "training_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data features:\n",
      "tfidf_message: 31208\n",
      "tfidf_message_stem: 21451\n",
      "tfidf_message_lemma: 24824\n",
      "tfidf_multi_message: 100000\n",
      "tfidf_multi_message_stem: 100000\n",
      "tfidf_multi_message_lemma: 100000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data features:\")\n",
    "for v in vectorizers:\n",
    "    for col in cols:\n",
    "        curr_vectorizer = vectorizers[v]\n",
    "        key = v + '_' + col\n",
    "        training_features[key] = curr_vectorizer.fit_transform(train[col])\n",
    "        print(key + \":\", len(curr_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x):\n",
    "    # x is the feature matrix of training data (count or tfidf)\n",
    "    \n",
    "    classifiers = {}\n",
    "    roc_auc_scores = {}\n",
    "\n",
    "    for col in model_cols:\n",
    "        y = train[col]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=79)\n",
    "\n",
    "        clf = logis_clf.fit(x_train, y_train)\n",
    "        predicted = clf.predict_proba(x_test)[:, 1]\n",
    "        score = metrics.roc_auc_score(y_test, predicted)\n",
    "\n",
    "        classifiers[col] = clf\n",
    "        roc_auc_scores[col] = score\n",
    "    \n",
    "    avg = 0\n",
    "    for key in roc_auc_scores:\n",
    "        print(\"Score for {}: \".format(key), roc_auc_scores[key])\n",
    "        avg += roc_auc_scores[key]\n",
    "\n",
    "    avg /= len(model_cols)\n",
    "    print(\"Final Score: \", avg)\n",
    "\n",
    "    return classifiers, roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "tfidf_message\n",
      "Score for request:  0.890395124485479\n",
      "Score for food:  0.952514171330649\n",
      "Score for shelter:  0.9322075454535048\n",
      "Score for water:  0.9424076732350254\n",
      "Score for medical_help:  0.8504895432705111\n",
      "Score for clothing:  0.9179631291158098\n",
      "Score for search_and_rescue:  0.7895612797324909\n",
      "Final Score:  0.8965054952319242\n",
      "\n",
      "tfidf_message_stem\n",
      "Score for request:  0.8929661799958425\n",
      "Score for food:  0.9533928887988452\n",
      "Score for shelter:  0.9352379799191924\n",
      "Score for water:  0.941698203488625\n",
      "Score for medical_help:  0.8573648118356896\n",
      "Score for clothing:  0.9155084559259197\n",
      "Score for search_and_rescue:  0.8037308075355\n",
      "Final Score:  0.8999856182142307\n",
      "\n",
      "tfidf_message_lemma\n",
      "Score for request:  0.8926734833871213\n",
      "Score for food:  0.9531425426933757\n",
      "Score for shelter:  0.9344066511123842\n",
      "Score for water:  0.9417577972073601\n",
      "Score for medical_help:  0.8508517733292139\n",
      "Score for clothing:  0.912916659613008\n",
      "Score for search_and_rescue:  0.7972525474110763\n",
      "Final Score:  0.8975716363933627\n",
      "\n",
      "tfidf_multi_message\n",
      "Score for request:  0.8934170000598496\n",
      "Score for food:  0.9532499092528343\n",
      "Score for shelter:  0.9269424630103863\n",
      "Score for water:  0.9453412501631214\n",
      "Score for medical_help:  0.8523230665970617\n",
      "Score for clothing:  0.9164463103722639\n",
      "Score for search_and_rescue:  0.7871524028784649\n",
      "Final Score:  0.8964103431905688\n",
      "\n",
      "tfidf_multi_message_stem\n",
      "Score for request:  0.8968167428834706\n",
      "Score for food:  0.9555958817669951\n",
      "Score for shelter:  0.9328439939204562\n",
      "Score for water:  0.9454543477315239\n",
      "Score for medical_help:  0.8602161306016926\n",
      "Score for clothing:  0.9158690389531241\n",
      "Score for search_and_rescue:  0.8011991065256759\n",
      "Final Score:  0.901142177483277\n",
      "\n",
      "tfidf_multi_message_lemma\n",
      "Score for request:  0.8965745112072877\n",
      "Score for food:  0.9549181798228953\n",
      "Score for shelter:  0.9340452038050763\n",
      "Score for water:  0.9454760972639089\n",
      "Score for medical_help:  0.8529360166767878\n",
      "Score for clothing:  0.9125560765858035\n",
      "Score for search_and_rescue:  0.7954197063264914\n",
      "Final Score:  0.8988465416697501\n"
     ]
    }
   ],
   "source": [
    "for type_model in training_features:\n",
    "    print('\\n' +type_model)\n",
    "    classifier, scores = training(training_features[type_model])\n",
    "    result_classifiers[type_model] = [classifier, scores]"
   ]
  }
 ]
}