{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize\n",
    "model_cols = ['request', 'food', 'shelter', 'water', 'medical_help', 'clothing', 'search_and_rescue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./preprocessed/training.csv\")\n",
    "test = pd.read_csv(\"./preprocessed/test.csv\")\n",
    "validation = pd.read_csv(\"./preprocessed/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TFIDF multi stemmed model\n",
    "vectorizer = TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range = (1,2), tokenizer = tokenizer, max_features=80000)\n",
    "features = vectorizer.fit_transform(train['message_stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logis_clf = LogisticRegression(C=2, solver='lbfgs', max_iter=1500)\n",
    "\n",
    "def training(x):\n",
    "    # x is the feature matrix of training data (count or tfidf)\n",
    "    \n",
    "    classifiers = {}\n",
    "    roc_auc_scores = {}\n",
    "\n",
    "    for col in model_cols:\n",
    "        y = train[col]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=79)\n",
    "\n",
    "        clf = logis_clf.fit(x_train, y_train)\n",
    "        predicted = clf.predict_proba(x_test)[:, 1]\n",
    "        score = metrics.roc_auc_score(y_test, predicted)\n",
    "\n",
    "        classifiers[col] = clf\n",
    "        roc_auc_scores[col] = score\n",
    "    \n",
    "    avg = 0\n",
    "    for key in roc_auc_scores:\n",
    "        print(\"Score for {}: \".format(key), roc_auc_scores[key])\n",
    "        avg += roc_auc_scores[key]\n",
    "\n",
    "    avg /= len(model_cols)\n",
    "    print(\"Final Score: \", avg)\n",
    "\n",
    "    roc_auc_scores['avg'] = avg\n",
    "    return classifiers, roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score for request:  0.8967788499165824\nScore for food:  0.9555114657988706\nScore for shelter:  0.933284959635372\nScore for water:  0.9454195484797078\nScore for medical_help:  0.8602839599558221\nScore for clothing:  0.9173147568180665\nScore for search_and_rescue:  0.8020588756162631\nFinal Score:  0.901521773745812\n"
     ]
    }
   ],
   "source": [
    "classifiers, scores = training(features)"
   ]
  }
 ]
}